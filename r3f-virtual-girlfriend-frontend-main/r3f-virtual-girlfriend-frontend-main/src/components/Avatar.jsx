/*
Auto-generated by: https://github.com/pmndrs/gltfjsx
Command: npx gltfjsx@6.2.3 public/models/64f1a714fe61576b46f27ca2.glb -o src/components/Avatar.jsx -k -r public
*/

import { useAnimations, useGLTF } from "@react-three/drei";
import { useFrame } from "@react-three/fiber";
import { button, useControls } from "leva";
import React, { useEffect, useRef, useState } from "react";

import * as THREE from "three";
import { useChat } from "../hooks/useChat";

const facialExpressions = {
  default: {},
  smile: {
    browInnerUp: 0.17,
    eyeSquintLeft: 0.4,
    eyeSquintRight: 0.44,
    noseSneerLeft: 0.1700000727403593,
    noseSneerRight: 0.14000002836874015,
    mouthPressLeft: 0.61,
    mouthPressRight: 0.41000000000000003,
  },
  funnyFace: {
    jawLeft: 0.63,
    mouthPucker: 0.53,
    noseSneerLeft: 1,
    noseSneerRight: 0.39,
    mouthLeft: 1,
    eyeLookUpLeft: 1,
    eyeLookUpRight: 1,
    cheekPuff: 0.9999924982764238,
    mouthDimpleLeft: 0.414743888682652,
    mouthRollLower: 0.32,
    mouthSmileLeft: 0.35499733688813034,
    mouthSmileRight: 0.35499733688813034,
  },
  sad: {
    mouthFrownLeft: 1,
    mouthFrownRight: 1,
    mouthShrugLower: 0.78341,
    browInnerUp: 0.452,
    eyeSquintLeft: 0.72,
    eyeSquintRight: 0.75,
    eyeLookDownLeft: 0.5,
    eyeLookDownRight: 0.5,
    jawForward: 1,
  },
  surprised: {
    eyeWideLeft: 0.5,
    eyeWideRight: 0.5,
    jawOpen: 0.351,
    mouthFunnel: 1,
    browInnerUp: 1,
  },
  angry: {
    browDownLeft: 1,
    browDownRight: 1,
    eyeSquintLeft: 1,
    eyeSquintRight: 1,
    jawForward: 1,
    jawLeft: 1,
    mouthShrugLower: 1,
    noseSneerLeft: 1,
    noseSneerRight: 0.42,
    eyeLookDownLeft: 0.16,
    eyeLookDownRight: 0.16,
    cheekSquintLeft: 1,
    cheekSquintRight: 1,
    mouthClose: 0.23,
    mouthFunnel: 0.63,
    mouthDimpleRight: 1,
  },
  crazy: {
    browInnerUp: 0.9,
    jawForward: 1,
    noseSneerLeft: 0.5700000000000001,
    noseSneerRight: 0.51,
    eyeLookDownLeft: 0.39435766259644545,
    eyeLookUpRight: 0.4039761421719682,
    eyeLookInLeft: 0.9618479575523053,
    eyeLookInRight: 0.9618479575523053,
    jawOpen: 0.9618479575523053,
    mouthDimpleLeft: 0.9618479575523053,
    mouthDimpleRight: 0.9618479575523053,
    mouthStretchLeft: 0.27893590769016857,
    mouthStretchRight: 0.2885543872656917,
    mouthSmileLeft: 0.5578718153803371,
    mouthSmileRight: 0.38473918302092225,
    tongueOut: 0.9618479575523053,
  },
};

// Enhanced viseme mapping for better lip-sync quality
const corresponding = {
  // Rhubarb phoneme to Three.js morph target mapping
  A: "viseme_PP",    // P, B, M sounds
  B: "viseme_kk",    // K, G sounds
  C: "viseme_I",     // I, Y sounds
  D: "viseme_AA",    // A sounds
  E: "viseme_O",     // O sounds
  F: "viseme_U",     // U, W sounds
  G: "viseme_FF",    // F, V sounds
  H: "viseme_TH",    // TH sounds
  X: "viseme_PP",    // Rest/silence

  // Additional mappings for better coverage
  I: "viseme_E",     // E sounds
  J: "viseme_CH",    // CH, J sounds
  K: "viseme_kk",    // Hard consonants
  L: "viseme_nn",    // L, N sounds
  M: "viseme_PP",    // M sounds
  N: "viseme_nn",    // N sounds
  O: "viseme_O",     // O sounds
  P: "viseme_PP",    // P sounds
  Q: "viseme_kk",    // Q sounds
  R: "viseme_RR",    // R sounds
  S: "viseme_SS",    // S, Z sounds
  T: "viseme_DD",    // T, D sounds
  U: "viseme_U",     // U sounds
  V: "viseme_FF",    // V sounds
  W: "viseme_U",     // W sounds
  Y: "viseme_I",     // Y sounds
  Z: "viseme_SS",    // Z sounds
};

let setupMode = false;

export function Avatar(props) {
  const { nodes, materials, scene } = useGLTF(
    "/models/64f1a714fe61576b46f27ca2.glb"
  );

  const { message, onMessagePlayed, chat } = useChat();

  const [lipsync, setLipsync] = useState();

  useEffect(() => {
    console.log(message);
    if (!message) {
      setAnimation("Idle");
      return;
    }
    // Safely set animation with fallback
    const animationName = message.animation || "Idle";
    if (animations.find(a => a.name === animationName)) {
      setAnimation(animationName);
    } else {
      console.warn(`Animation "${animationName}" not found, using Idle`);
      setAnimation("Idle");
    }
    setFacialExpression(message.facialExpression || "default");
    setLipsync(message.lipsync);

    // Handle audio - works with or without audio data
    if (message.audio) {
      // Audio is available from backend - play it
      const audio = new Audio("data:audio/mp3;base64," + message.audio);
      audio.play();
      setAudio(audio);
      audio.onended = onMessagePlayed;
    } else {
      // No audio from backend - use Web Speech API (browser native TTS)
      console.log("Using Web Speech API for TTS");
      setAudio(null);

      if ('speechSynthesis' in window) {
        // Enhanced text cleaning and emoji replacement for better speech
        let cleanText = message.text
          // Replace common emojis with spoken equivalents
          .replace(/ðŸ˜Š|ðŸ˜„|ðŸ˜ƒ|ðŸ™‚/g, ' *smiles* ')
          .replace(/ðŸ˜¢|ðŸ˜­|ðŸ¥º/g, ' *sighs sadly* ')
          .replace(/ðŸ˜|ðŸ¥°|ðŸ’–|ðŸ’•|â¤ï¸/g, ' *with love* ')
          .replace(/ðŸ˜˜|ðŸ’‹/g, ' *kisses* ')
          .replace(/ðŸŒ¸|ðŸŒ¹|ðŸŒº/g, ' *sweetly* ')
          .replace(/âœ¨|ðŸ’«|â­|ðŸŒŸ/g, ' *sparkles* ')
          .replace(/ðŸŽ‰|ðŸŽŠ/g, ' *excitedly* ')
          .replace(/ðŸ’Ž|ðŸ‘‘/g, ' *proudly* ')
          .replace(/ðŸ”¥|ðŸ’¥/g, ' *passionately* ')
          .replace(/ðŸ¦‹|ðŸŒ™/g, ' *dreamily* ')
          // Remove remaining emojis and special characters
          .replace(/[^\w\s.,!?;:'"()\-*]/g, '')
          // Clean up multiple spaces and trim
          .replace(/\s+/g, ' ')
          .trim();

        // Add natural pauses for better speech rhythm
        cleanText = cleanText
          .replace(/\. /g, '. *pause* ')
          .replace(/! /g, '! *pause* ')
          .replace(/\? /g, '? *pause* ');

        console.log(`Original: "${message.text}"`);
        console.log(`Cleaned for TTS: "${cleanText}"`);

        const utterance = new SpeechSynthesisUtterance(cleanText);

        // Configure voice settings for optimal girlfriend experience
        if (femaleVoice) {
          utterance.voice = femaleVoice;
          console.log(`Using high-quality voice: ${femaleVoice.name}`);

          // Optimize settings based on voice type
          if (femaleVoice.name.includes('Natural') || femaleVoice.name.includes('Premium')) {
            // Microsoft Natural and Apple Premium voices - minimal adjustment needed
            utterance.rate = 0.95;
            utterance.pitch = 1.0; // Natural voices don't need pitch adjustment
            utterance.volume = 0.9;
          } else if (femaleVoice.name.includes('Google')) {
            // Google voices - slightly slower and higher pitch
            utterance.rate = 0.85;
            utterance.pitch = 1.1;
            utterance.volume = 0.8;
          } else {
            // Default settings for other voices
            utterance.rate = 0.9;
            utterance.pitch = 1.2;
            utterance.volume = 0.8;
          }
        } else {
          console.log("Using default system voice");
          utterance.rate = 0.9;
          utterance.pitch = 1.2;
          utterance.volume = 0.8;
        }

        // Try to find the best female voice using research-based recommendations
        const voices = speechSynthesis.getVoices();

        // Priority order based on Web Speech API research and quality
        const preferredVoices = [
          // Microsoft Natural Voices (highest quality)
          'Microsoft Aria Online (Natural) - English (United States)',
          'Microsoft Emma Online (Natural) - English (United States)',
          'Microsoft Jenny Online (Natural) - English (United States)',
          'Microsoft Michelle Online (Natural) - English (United States)',
          'Microsoft Ana Online (Natural) - English (United States)',

          // Apple Premium Voices (high quality)
          'Samantha', 'Samantha (Enhanced)', 'Samantha (Premium)',
          'Ava', 'Ava (Enhanced)', 'Ava (Premium)',
          'Susan', 'Susan (Enhanced)', 'Susan (Premium)',
          'Allison', 'Allison (Enhanced)', 'Allison (Premium)',
          'Zoe', 'Zoe (Enhanced)', 'Zoe (Premium)',

          // Google Voices (good quality)
          'Google UK English Female',
          'Google US English Female',
          'Google female voice',

          // Chrome OS Android Voices (good quality)
          'Android Speech Recognition and Synthesis from Google en-us-x-tpc-network',
          'Android Speech Recognition and Synthesis from Google en-gb-x-rjs-network',

          // Fallback options
          'Microsoft Zira Desktop - English (United States)',
          'Microsoft Hazel Desktop - English (Great Britain)',
          'female', 'woman'
        ];

        // Find the best available voice
        let femaleVoice = null;
        for (const preferredName of preferredVoices) {
          femaleVoice = voices.find(voice =>
            voice.name === preferredName ||
            voice.name.toLowerCase().includes(preferredName.toLowerCase())
          );
          if (femaleVoice) break;
        }

        // If no preferred voice found, try generic female detection
        if (!femaleVoice) {
          femaleVoice = voices.find(voice =>
            voice.name.toLowerCase().includes('female') ||
            voice.name.toLowerCase().includes('woman') ||
            (voice.lang.startsWith('en') && voice.name.toLowerCase().includes('f'))
          );
        }

        utterance.onend = () => {
          console.log("Speech synthesis completed");
          onMessagePlayed();
        };

        utterance.onerror = (event) => {
          console.error("Speech synthesis error:", event.error);
          // Fallback to timer if speech fails
          const textLength = cleanText.length;
          const readingTime = Math.max(2000, textLength * 50);
          setTimeout(() => {
            onMessagePlayed();
          }, readingTime);
        };

        // Start speaking
        speechSynthesis.speak(utterance);
      } else {
        // Fallback for browsers without speech synthesis
        console.log("Speech synthesis not supported - using timer");
        const textLength = message.text.length;
        const readingTime = Math.max(2000, textLength * 50);
        setTimeout(() => {
          onMessagePlayed();
        }, readingTime);
      }
    }
  }, [message]);

  const { animations } = useGLTF("/models/animations.glb");

  const group = useRef();
  const { actions, mixer } = useAnimations(animations, group);

  // Suppress THREE.js PropertyBinding warnings (cosmetic only)
  useEffect(() => {
    const originalWarn = console.warn;
    console.warn = (...args) => {
      const message = args[0];
      if (typeof message === 'string' && message.includes('THREE.PropertyBinding: Trying to update node for track')) {
        return; // Suppress these specific warnings
      }
      originalWarn.apply(console, args);
    };

    return () => {
      console.warn = originalWarn;
    };
  }, []);
  const [animation, setAnimation] = useState(
    animations.find((a) => a.name === "Idle") ? "Idle" : (animations[0]?.name || "Idle") // Check if Idle animation exists otherwise use first animation
  );
  useEffect(() => {
    if (actions && actions[animation] && mixer) {
      actions[animation]
        .reset()
        .fadeIn(mixer.stats?.actions?.inUse === 0 ? 0 : 0.5)
        .play();
    }
    return () => {
      if (actions && actions[animation]) {
        try {
          actions[animation].fadeOut(0.5);
        } catch (error) {
          console.warn('Error fading out animation:', error);
        }
      }
    };
  }, [animation, actions, mixer]);

  const lerpMorphTarget = (target, value, speed = 0.1) => {
    scene.traverse((child) => {
      if (child.isSkinnedMesh && child.morphTargetDictionary) {
        const index = child.morphTargetDictionary[target];
        if (
          index === undefined ||
          child.morphTargetInfluences[index] === undefined
        ) {
          return;
        }
        child.morphTargetInfluences[index] = THREE.MathUtils.lerp(
          child.morphTargetInfluences[index],
          value,
          speed
        );

        if (!setupMode) {
          try {
            set({
              [target]: value,
            });
          } catch (e) {}
        }
      }
    });
  };

  const [blink, setBlink] = useState(false);
  const [winkLeft, setWinkLeft] = useState(false);
  const [winkRight, setWinkRight] = useState(false);
  const [facialExpression, setFacialExpression] = useState("");
  const [audio, setAudio] = useState();
  const [speechVoices, setSpeechVoices] = useState([]);

  // Load available speech synthesis voices
  useEffect(() => {
    if ('speechSynthesis' in window) {
      const loadVoices = () => {
        const voices = speechSynthesis.getVoices();
        setSpeechVoices(voices);
        console.log(`Loaded ${voices.length} speech synthesis voices`);

        // Log available female voices for debugging
        const femaleVoices = voices.filter(voice =>
          voice.name.toLowerCase().includes('female') ||
          voice.name.toLowerCase().includes('woman') ||
          voice.name.toLowerCase().includes('zira') ||
          voice.name.toLowerCase().includes('hazel') ||
          voice.name.toLowerCase().includes('susan') ||
          voice.name.toLowerCase().includes('samantha')
        );
        console.log('Available female voices:', femaleVoices.map(v => v.name));
      };

      // Load voices immediately
      loadVoices();

      // Also load when voices change (some browsers load them asynchronously)
      speechSynthesis.onvoiceschanged = loadVoices;
    }
  }, []);

  useFrame(() => {
    !setupMode &&
      Object.keys(nodes.EyeLeft.morphTargetDictionary).forEach((key) => {
        const mapping = facialExpressions[facialExpression];
        if (key === "eyeBlinkLeft" || key === "eyeBlinkRight") {
          return; // eyes wink/blink are handled separately
        }
        if (mapping && mapping[key]) {
          lerpMorphTarget(key, mapping[key], 0.1);
        } else {
          lerpMorphTarget(key, 0, 0.1);
        }
      });

    lerpMorphTarget("eyeBlinkLeft", blink || winkLeft ? 1 : 0, 0.5);
    lerpMorphTarget("eyeBlinkRight", blink || winkRight ? 1 : 0, 0.5);

    // ENHANCED LIPSYNC
    if (setupMode) {
      return;
    }

    const appliedMorphTargets = [];
    if (message && lipsync && audio) {
      const currentAudioTime = audio.currentTime;

      // Find current and next mouth cues for smoother transitions
      let currentCue = null;
      let nextCue = null;

      for (let i = 0; i < lipsync.mouthCues.length; i++) {
        const mouthCue = lipsync.mouthCues[i];

        if (currentAudioTime >= mouthCue.start && currentAudioTime <= mouthCue.end) {
          currentCue = mouthCue;
          nextCue = lipsync.mouthCues[i + 1] || null;
          break;
        }
      }

      if (currentCue) {
        const visemeTarget = corresponding[currentCue.value];
        if (visemeTarget) {
          appliedMorphTargets.push(visemeTarget);

          // Calculate intensity based on position within the cue
          const cueProgress = (currentAudioTime - currentCue.start) / (currentCue.end - currentCue.start);
          const intensity = Math.sin(cueProgress * Math.PI) * 0.8 + 0.2; // Smooth curve

          lerpMorphTarget(visemeTarget, intensity, 0.15); // Faster lerp for responsiveness
        }
      }

      // Smooth transition to next cue if close
      if (nextCue && currentCue) {
        const timeToNext = nextCue.start - currentAudioTime;
        if (timeToNext < 0.1 && timeToNext > 0) { // 100ms lookahead
          const nextVisemeTarget = corresponding[nextCue.value];
          if (nextVisemeTarget && nextVisemeTarget !== corresponding[currentCue.value]) {
            const transitionIntensity = (0.1 - timeToNext) / 0.1;
            lerpMorphTarget(nextVisemeTarget, transitionIntensity * 0.3, 0.1);
          }
        }
      }
    }

    // Reset all other visemes more smoothly
    Object.values(corresponding).forEach((value) => {
      if (appliedMorphTargets.includes(value)) {
        return;
      }
      lerpMorphTarget(value, 0, 0.08); // Slightly faster reset for cleaner transitions
    });
  });

  useControls("FacialExpressions", {
    chat: button(() => chat()),
    winkLeft: button(() => {
      setWinkLeft(true);
      setTimeout(() => setWinkLeft(false), 300);
    }),
    winkRight: button(() => {
      setWinkRight(true);
      setTimeout(() => setWinkRight(false), 300);
    }),
    animation: {
      value: animation,
      options: animations.map((a) => a.name),
      onChange: (value) => setAnimation(value),
    },
    facialExpression: {
      options: Object.keys(facialExpressions),
      onChange: (value) => setFacialExpression(value),
    },
    enableSetupMode: button(() => {
      setupMode = true;
    }),
    disableSetupMode: button(() => {
      setupMode = false;
    }),
    logMorphTargetValues: button(() => {
      const emotionValues = {};
      Object.keys(nodes.EyeLeft.morphTargetDictionary).forEach((key) => {
        if (key === "eyeBlinkLeft" || key === "eyeBlinkRight") {
          return; // eyes wink/blink are handled separately
        }
        const value =
          nodes.EyeLeft.morphTargetInfluences[
            nodes.EyeLeft.morphTargetDictionary[key]
          ];
        if (value > 0.01) {
          emotionValues[key] = value;
        }
      });
      console.log(JSON.stringify(emotionValues, null, 2));
    }),
  });

  const [, set] = useControls("MorphTarget", () =>
    Object.assign(
      {},
      ...Object.keys(nodes.EyeLeft.morphTargetDictionary).map((key) => {
        return {
          [key]: {
            label: key,
            value: 0,
            min: nodes.EyeLeft.morphTargetInfluences[
              nodes.EyeLeft.morphTargetDictionary[key]
            ],
            max: 1,
            onChange: (val) => {
              if (setupMode) {
                lerpMorphTarget(key, val, 1);
              }
            },
          },
        };
      })
    )
  );

  useEffect(() => {
    let blinkTimeout;
    const nextBlink = () => {
      blinkTimeout = setTimeout(() => {
        setBlink(true);
        setTimeout(() => {
          setBlink(false);
          nextBlink();
        }, 200);
      }, THREE.MathUtils.randInt(1000, 5000));
    };
    nextBlink();
    return () => clearTimeout(blinkTimeout);
  }, []);

  return (
    <group {...props} dispose={null} ref={group}>
      <primitive object={nodes.Hips} />
      <skinnedMesh
        name="Wolf3D_Body"
        geometry={nodes.Wolf3D_Body.geometry}
        material={materials.Wolf3D_Body}
        skeleton={nodes.Wolf3D_Body.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Outfit_Bottom"
        geometry={nodes.Wolf3D_Outfit_Bottom.geometry}
        material={materials.Wolf3D_Outfit_Bottom}
        skeleton={nodes.Wolf3D_Outfit_Bottom.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Outfit_Footwear"
        geometry={nodes.Wolf3D_Outfit_Footwear.geometry}
        material={materials.Wolf3D_Outfit_Footwear}
        skeleton={nodes.Wolf3D_Outfit_Footwear.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Outfit_Top"
        geometry={nodes.Wolf3D_Outfit_Top.geometry}
        material={materials.Wolf3D_Outfit_Top}
        skeleton={nodes.Wolf3D_Outfit_Top.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Hair"
        geometry={nodes.Wolf3D_Hair.geometry}
        material={materials.Wolf3D_Hair}
        skeleton={nodes.Wolf3D_Hair.skeleton}
      />
      <skinnedMesh
        name="EyeLeft"
        geometry={nodes.EyeLeft.geometry}
        material={materials.Wolf3D_Eye}
        skeleton={nodes.EyeLeft.skeleton}
        morphTargetDictionary={nodes.EyeLeft.morphTargetDictionary}
        morphTargetInfluences={nodes.EyeLeft.morphTargetInfluences}
      />
      <skinnedMesh
        name="EyeRight"
        geometry={nodes.EyeRight.geometry}
        material={materials.Wolf3D_Eye}
        skeleton={nodes.EyeRight.skeleton}
        morphTargetDictionary={nodes.EyeRight.morphTargetDictionary}
        morphTargetInfluences={nodes.EyeRight.morphTargetInfluences}
      />
      <skinnedMesh
        name="Wolf3D_Head"
        geometry={nodes.Wolf3D_Head.geometry}
        material={materials.Wolf3D_Skin}
        skeleton={nodes.Wolf3D_Head.skeleton}
        morphTargetDictionary={nodes.Wolf3D_Head.morphTargetDictionary}
        morphTargetInfluences={nodes.Wolf3D_Head.morphTargetInfluences}
      />
      <skinnedMesh
        name="Wolf3D_Teeth"
        geometry={nodes.Wolf3D_Teeth.geometry}
        material={materials.Wolf3D_Teeth}
        skeleton={nodes.Wolf3D_Teeth.skeleton}
        morphTargetDictionary={nodes.Wolf3D_Teeth.morphTargetDictionary}
        morphTargetInfluences={nodes.Wolf3D_Teeth.morphTargetInfluences}
      />
    </group>
  );
}

useGLTF.preload("/models/64f1a714fe61576b46f27ca2.glb");
useGLTF.preload("/models/animations.glb");
